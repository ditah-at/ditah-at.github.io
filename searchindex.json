[
  {
    "id": "derla",
    "title": "Digitale Erinnerungslandschaft Österreichs (DERLA)",
    "content": "Die Digitale Erinnerungslandschaft Österreichs (DERLA) ist ein interdisziplinäres Dokumentations- und Vermittlungsprojekt. Es dokumentiert die Erinnerungsorte und -zeichen für die Opfer sowie die Orte des Terrors des Nationalsozialismus in Österreich und setzt sich die kritische Auseinandersetzung mit dem Nationalsozialismus und der Erinnerung an ihn und seine Opfer zum Ziel.DERLA unterscheidet zwischen manifesten und nicht-manifesten Erinnerungsorten. Unter manifesten Erinnerungsorten werden jene verstanden, die durch Erinnerungszeichen (Denkmäler, Gedenktafeln, u.a.) als Erinnerungsorte in der Öffentlichkeit sichtbar gemacht werden. Nicht-manifeste Erinnerungsorte sind Erinnerungsorte, die bislang über kein öffentlich sichtbares Erinnerungszeichen verfügen, jedoch einen historischen Bezug zu Opfern und/oder dem Terror des Nationalsozialismus und Faschismus aufweisen. Ihnen wird mit DERLA ein virtuelles Zeichen gesetzt.Jeder Erinnerungsort wird mit Informationen zum historischen Ereignis oder den Personen, an die am Ort erinnert wird, ebenso wie zur Geschichte des Erinnerungszeichens/-ortes selbst versehen. Weiters werden die Erinnerungszeichen/-orte zur besseren Orientierung der NutzerInnen sowie in Bezug auf die Vermittlungsangebote unterschiedlichen Kategorien zugeordnet. Diese Kategorien orientieren sich an der Intention der Stifter und Errichter der Erinnerungszeichen sowie im Fall der nicht-manifesten Erinnerungsorte an den historischen Ereignissen/Erfahrungen, die mit dem jeweiligen Ort verbunden sind.DERLA besteht aus vier wesentlichen Elementen: Eine interaktive Karte der Erinnerung führt zu den einzelnen Erinnerungsorten und -zeichen und macht deren Geschichte sichtbar. Mittels Filter- und Suchfunktionen können Sie umfangreiche Recherchen durchführen.    Im Archiv der Namen werden all jene Menschen, die auf den Erinnerungszeichen genannt und erinnert werden, biografisch vorgestellt. DERLA setzt ihnen ein virtuelles Erinnerungszeichen. Derzeit sind mehr als 1300 Biographien in DERLA erfasst.    Im Vermittlungsportal finden sich ortsgebundene und ortsungebundene Angebote für die schulische Vermittlungsarbeit. Das historische Lernen mit DERLA kann sowohl vor Ort als auch im Klassenzimmer erfolgen.    Die Wege der Erinnerung führen entlang kuratierter Routen in spezifische Themen der Geschichte des Nationalsozialismus und der Erinnerungskultur ein. Sie sind virtuelle Ausstellungen zu spezifischen Themen. Schlagworte:interaktive und multimodale Erinnerungs(land)karte; digitale Erinnerungslandschaft; österreichische Erinnerungsorte und -zeichen für die Opfer sowie die Orte des Terrors des Nationalsozialismus, virtuelle Filter- und Suchfunktion; Namensarchiv, Vermittlungsportal, schulische Vermittlungsarbeit",
    "url": "derla.html"
  },
  {
    "id": "m3r",
    "title": "Multimodale Repräsentation & Analyse von Manuskripten",
    "content": "Forschung an historischen Manuskripten wird zunehmend von technischen Disziplinen unterstützt: Multi- und Hyperspektralbildgebung unterstützt die Wiederherstellung von degradierten oder absichtlich entfernten Inhalten; spektroskopische Analysemethoden werden zur Identifizierung und Charakterisierung von Tinten, Pigmenten und Substraten eingesetzt, was wiederum Hinweise zur Rekonstruktion des Ursprungs und der Geschichte eines Manuskripts liefert.Jede Untersuchungsrichtung erzeugt spezifische digitale Artefakte wie Bildmaterial, spektroskopische Messungen oder hochrangige Analyseergebnisse. Wenn die verschiedenen Untersuchungen von unterschiedlichen Institutionen und zu verschiedenen Zeiten durchgeführt werden, existieren die erzeugten Artefakte meist unabhängig voneinander und ohne gemeinsamen Bezugsrahmen. Dadurch ist das Potenzial zur Wiederverwendung in interdisziplinärer Forschung begrenzt und ihr effektiver Lebenszyklus endet oft mit den Forschungsprojekten, in denen sie erworben wurden. Multi-Modal Manuscript Representations (M3R) ist ein Repositorium für die Archivierung und Verbreitung von Manuskriptforschungsdaten, in dem die verschiedenen digitalen Artefakte räumlich und logisch miteinander verknüpft sind. Im Hinblick auf die Langzeitarchivierung und linked open data (LOD) wird besonderer Wert auf die Verwendung etablierter und offener Standards für Daten und Metadaten gelegt. Die resultierenden virtuellen Objekte werden über technische Schnittstellen, aber auch über einen interaktiven Web-Viewer verbreitet. Somit werden die im Repositorium verfügbaren Daten langfristig nicht nur für Naturwissenschaften und Technik, sondern auch für Forschung und Bildung in den Geisteswissenschaften zugänglich gemacht.'Everything is connected'Abbildung 2 versucht, die konzeptionellen Ideen hinter M3R zu visualisieren. Auf der obersten Ebene beginnen wir mit dem Manuskript, einem physischen Objekt, das in einem Archiv oder einer Bibliothek aufbewahrt und inventarisiert wird - es kann in Form eines Kodex (eines „Buches“), einer Sammlung von Fragmenten oder sogar einer Rolle vorliegen. Informationen, die das gesamte Manuskript oder größere Teile davon betreffen – z.B. Provenienzinformationen, konservatorischer Zustand, Schriftmerkmale oder Transkriptionen – werden im etablierten TEI-Format gespeichert.Das Manuskript wird in Seiten unterteilt, das sind die Flächen, die mit Text beschrieben sind. Bei Kodizes und Fragmenten entsprechen die Seiten meist den Blättern; bei Rollen oder anderen Objekten ist die Definition liberaler. In jedem Fall wird der Bereich einer Seite technisch durch ein Referenzbild definiert – in der Regel ein Naturfarbbild, das die jeweilige Oberfläche zeigt. Jedes zusätzliche Bildmaterial der Seite, z.B. multispektrale Bilder oder Elementverteilungskarten, ist mit einer 2D-Transformation ausgestattet, die die korrekte Ausrichtung zum Referenzbild definiert.Innerhalb einer Seite können mehrere Messpunkte definiert werden: Sie enthalten punktuelle Informationen über die Manuskriptoberfläche, wie z.B. spektroskopische Messungen, die an dieser Stelle durchgeführt wurden, oder die identifizierten Materialien. Die Positionen der Messpunkte werden in Pixelkoordinaten innerhalb des Referenzbildes der jeweiligen Seite angegeben.Genau wie die hochrangigen Informationen über das Manuskript im TEI-Format gespeichert werden, sollten Informationen über einzelne Seiten, Messpunkte und digitale Artefakte unter Verwendung etablierter und/oder offener Standards modelliert werden. Zum Beispiel werden Bilder als TIFF gespeichert, spektroskopische Messungen als JCAMP-DX und die an Messpunkten identifizierten Materialien (z.B. chemische Elemente, Tintensorten, Pigmente) über Konzepte einer Taxonomie im SKOS-Format angegeben.Der „Klebstoff“ zur Verbindung aller zu einer bestimmten Seite gehörenden Informationen wird durch den METS-Standard bereitgestellt. Er ermöglicht die Modellierung der semantischen und räumlichen Beziehungen zwischen den einzelnen digitalen Artefakten sowie die Speicherung von Metadaten über die verwendeten Messgeräte. Figure2 Abbildung 2 'Easy access'Ein Prototyp-Repository, das den oben skizzierten Konzepten folgt, ist auf der GAMS-Infrastruktur der Uni Graz implementiert, einschließlich einer intuitiven grafischen Benutzeroberfläche in Form einer Website.Auf der Website kann der Benutzer die Erkundung aus zwei Perspektiven starten: Aus einer objektzentrierten Perspektive ist der Benutzer an einem bestimmten Manuskript interessiert und findet die verschiedenen damit verbundenen digitalen Repräsentationen und Messungen; aus einer materialzentrierten Perspektive ist der Benutzer an dem Vorkommen bestimmter Tinten, Pigmente oder anderer Substanzen interessiert und findet die Manuskripte und Messpunkte, an denen sie nachgewiesen wurden. Abbildung 3 gibt einen ersten Eindruck der Möglichkeiten; jedoch sagt praktische Erfahrung mehr als tausend Bilder, und der interessierte Leser kann den tatsächlichen Prototyp ausprobieren.Zusätzlich zu diesem benutzerfreundlichen Zugangsmodus werden technische Schnittstellen für automatisiertes Data Harvesting oder die Integration in Drittanwendungen bereitgestellt: IIIF-Bild- und Präsentations-API SPARQL-Endpunkt Direkter Zugriff auf originale Datenströme Umfassende Metadaten in standardisierten Formaten für alle digitalen Objekte Erntbarer OAI-PMH-Endpunkt. Schlagworte:digitale Transformation der Handschriftenforschung; es geht um Philologie, Paläographie, Kodikologie, Möglichkeiten fotografischer Dokumentation, Multispektralfotografie, Erfassung dreidimensionaler Oberflächenstruktur und Dokumentenanalyse; richtet sich primär an Studierende",
    "url": "m3r.html"
  },
  {
    "id": "dhlehre_de",
    "title": "DH Lehre an der Uni Wien",
    "content": "Künstliche Intelligenz - Prompt Engineering Text zu Text: Tauchen Sie ein in die Welt der Text-zu-Text-KI mit dieser Ressource über Prompt Engineering. Lernen Sie, wie Sie präzise Eingabeaufforderungen erstellen, um KI bei der Generierung der gewünschten Textausgaben zu unterstützen und so Anwendungen für Chatbots, Inhaltserstellung und Sprachübersetzung zu verbessern. Durch die Beherrschung verschiedener Techniken werden Sie die Effizienz und Genauigkeit von KI-Interaktionen verbessern und Antworten auf spezifische Bedürfnisse in der geisteswissenschaftlichen Forschung und darüber hinaus zuschneiden.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Künstlicher Intelligenz von Emily Genatowski, die auf dem von ihr entwickelten und an der Universität Wien unterrichteten Kurs Künstliche Intelligenz und große Sprachmodelle in der geisteswissenschaftlichen Forschung basieren.  Einführung in fortgeschrittene Bilderzeugungstechniken: Erforschen Sie fortgeschrittene KI-Bilderzeugungstechniken in dieser Ressource, die Ihnen helfen soll, mit KI-Tools effizient und genau zu arbeiten. Lernen Sie, wie Sie Methoden wie Wortgewichtung und narrative Elemente nutzen können, um die Verbindung zwischen Ihren Vorstellungen und der KI-Ausgabe herzustellen. Dieser Leitfaden vermittelt Ihnen die Fähigkeiten, diese Techniken effektiv einzusetzen und Kunst und Technologie zu vereinen, um die digitale Bildgestaltung zu verändern.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Künstlicher Intelligenz von Emily Genatowski, die auf dem von ihr entwickelten und an der Universität Wien unterrichteten Kurs Künstliche Intelligenz und große Sprachmodelle in der geisteswissenschaftlichen Forschung basieren.  Künstliche Intelligenz Prompt Engineering Rechtliche, gesellschaftliche und ethische Fragen: Diese Ressource gibt eine Einführung in die ethischen, gesellschaftlichen und rechtlichen Komplexitäten der Künstlichen Intelligenz und konzentriert sich dabei auf die Herausforderungen, die sich aus ihrer Entwicklung und Umsetzung ergeben. Es werden potenzielle Risiken wie Voreingenommenheit, Datenschutz, Autonomie und Arbeitsplatzverdrängung anhand von Fallstudien untersucht, um Probleme aus der Praxis aufzuzeigen. Die Ressource zielt darauf ab, den Lernenden die Fähigkeit zum kritischen Denken zu vermitteln, um die Auswirkungen der KI zu bewerten und mit ihren ethischen und rechtlichen Folgen verantwortungsvoll umzugehen.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Künstlicher Intelligenz von Emily Genatowski, die auf dem von ihr entwickelten und an der Universität Wien unterrichteten Kurs Künstliche Intelligenz und große Sprachmodelle in der geisteswissenschaftlichen Forschung basieren.  Angewandte Künstliche Intelligenz: Diese Ressource erforscht die transformativen Auswirkungen von Künstlicher Intelligenz in verschiedenen Sektoren, einschließlich Gesundheitswesen, Finanzwesen, Einzelhandel, Produktion und mehr. Durch die Untersuchung der einzigartigen Vorteile, Herausforderungen und des zukünftigen Potenzials von KI erhalten die Lernenden einen Einblick in die Art und Weise, wie KI traditionelle Praktiken umgestaltet und welche Rolle sie in Zukunft spielen wird. Nach Abschluss des Kurses werden die Lernenden in der Lage sein, die aktuellen Anwendungen von KI zu verstehen, ihre Grenzen zu diskutieren und ihre zukünftigen Einsatzmöglichkeiten in verschiedenen Bereichen vorherzusagen.  Diese Ressource ist Teil einer Gruppe von Ressourcen über Künstliche Intelligenz von Emily Genatowski, die auf dem von ihr entwickelten und an der Universität Wien unterrichteten Kurs basieren.  Prosopographie: Was ist eine Person? Das Schlüsselkonzept in dieser Ressource ist das Prosopon, ein unschätzbares Werkzeug in der Geschichts- und Literaturwissenschaft, das eine gesammelte literarische Darstellung einer Person darstellt. Ein Prosopon umfasst alle Formen von Informationen über eine Person, die aus verschiedenen Quellen wie Texten, Aufzeichnungen und Artefakten stammen. Durch das Studium von Prosoponen können wir umfassende Porträts von Personen aus der Vergangenheit zusammenstellen, auch wenn diese Porträts manchmal fragmentarisch oder verzerrt sind. Dieser Ansatz hilft uns, die gesellschaftlichen Rollen, die persönlichen Beziehungen und die historische Bedeutung von Einzelpersonen zu verstehen, und liefert einen reicheren Kontext der Vergangenheit.  Diese Ressource ist Teil einer Gruppe von Ressourcen zur Prosopographie, die von James Baille und Daniel Knox verfasst und von Emily Genatowski auf Dariah Campus zusammengestellt wurden, basierend auf dem an der Universität Wien unterrichteten Kurs Prosopographie und Analyse sozialer Netzwerke.  Prosopographie: Identität: Diese Ressource behandelt die Identitätstheorie in der Prosopographie und konzentriert sich auf Merkmale wie Rollen, Titel, Alter, ethnische Zugehörigkeit, Sexualität, Geschlecht und Religion. Sie hebt die Komplexität dieser Identitäten hervor, die fließend und vielschichtig sind und sich im Laufe der Zeit verändern können. Die Ressource zielt darauf ab, die Lernenden in die Lage zu versetzen, historische Quellen kritisch zu analysieren und die dynamische Natur der Identitätskonstruktion und -darstellung zu verstehen.  Diese Ressource ist Teil einer Gruppe von Ressourcen zur Prosopographie, die von James Baille und Daniel Knox verfasst und von Emily Genatowski auf Dariah Campus zusammengestellt wurden, basierend auf dem an der Universität Wien unterrichteten Kurs Prosopographie und Analyse sozialer Netzwerke.  Prosopographie: Umfang einer Datenbank: Diese Ressource erörtert die Bedeutung der Definition des Umfangs eines Datenbankprojekts in den Geistes- und Sozialwissenschaften. Es wird die Notwendigkeit betont, Grenzen zu setzen, um sicherzustellen, dass das Projekt überschaubar ist, mit den Forschungsfragen übereinstimmt und andere Forscher über den Inhalt der Datenbank informiert. Die Lernenden verstehen die Bedeutung des formalen Scopings, unterscheiden zwischen Quellen- und Modell-Scoping und lernen die wesentlichen Fragen kennen, die beim Scoping einer Datenbank zu stellen sind.  Diese Ressource ist Teil einer Gruppe von Ressourcen zur Prosopographie, die von James Baille und Daniel Knox verfasst und von Emily Genatowski auf Dariah Campus zusammengestellt wurden, basierend auf der Lehrveranstaltung an der Universität Wien mit dem Titel Prosopography and Social Network Analysis.   Daten und Datenbanken: Eine Einführung: Datenbanken sind für das moderne Informationsmanagement von grundlegender Bedeutung und ermöglichen die strukturierte Sammlung und Analyse von Daten. Dieser Kurs schließt die Lücke für geistes- und sozialwissenschaftliche ForscherInnen und bietet einen Überblick über die technischen Fähigkeiten, die für die Abfrage und Erstellung von Datenbanken erforderlich sind, und geht gleichzeitig auf die besonderen Herausforderungen ein, die geisteswissenschaftliche Daten darstellen. Lernen Sie, wie Sie Datenbanken effektiv nutzen können, um Ihre Forschung zu verbessern, von der Projektplanung über die Datenspeicherung bis hin zur Berücksichtigung ethischer Aspekte.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Daten und Datenbanken, die von James Baille und Daniel Knox geschrieben und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurden.  Datenbanken: Von der Quelle zu den Daten: Diese Ressource erörtert die einzigartigen Merkmale und Herausforderungen von geistes- und sozialwissenschaftlichen Daten, die sich erheblich von wissenschaftlichen Daten unterscheiden. Es werden Themen wie der nicht-experimentelle Charakter, die Quellenabhängigkeit, die hohe Komplexität und die Variabilität der Datenmenge und -konsistenz hervorgehoben. Der Leitfaden befasst sich auch mit der Bedeutung des Verständnisses von Datenerfassungsprozessen, Metadaten und den Auswirkungen der Klassifizierung und Strukturierung von Daten auf die Erstellung von Datenbanken in den Geisteswissenschaften.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Daten und Datenbanken, die von James Baille und Daniel Knox geschrieben und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurden.   Entity-Relationship-Datenmodell: In dieser Ressource werden die Lernenden die Bedeutung der Definition von Entitäten - Objekten mit bestimmten Merkmalen - innerhalb eines bestimmten Feldes verstehen. Die Lernenden werden Assoziationen (Beziehungen zwischen Entitäten), Attribute (elementare Daten über Entitäten), Identifikatoren (eindeutige Attribute zur Unterscheidung von Entitäten) und Kardinalitäten (Maßeinheiten für die Beziehung zwischen Entitäten) untersuchen. Wenn Sie diese Konzepte beherrschen, können Sie Daten in verschiedenen Bereichen effektiv modellieren und verwalten.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Daten und Datenbanken, die von James Baille und Daniel Knox geschrieben und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurden.  Abgrenzung eines Datenbankprojekts: Diese Ressource hilft den Lernenden, die Bedeutung des Scopings von Prosopographie-Projekten zu verstehen, und leitet Sie bei der Festlegung eines Umfangs auf der Grundlage von Forschungsfragen und Schlüsselfaktoren an. Durch eine klare Definition des Umfangs können Forscher ihre Bemühungen straffen, sich auf relevante Daten konzentrieren und aussagekräftige Ergebnisse erzielen. Lernen Sie, effektive Grenzen zu setzen, klare Projektparameter zu definieren und sicherzustellen, dass die Forschung sowohl zielgerichtet als auch umfassend ist.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Daten und Datenbanken, die von James Baille und Daniel Knox geschrieben und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurden.  Daten-Ethik: Diese Ressource erörtert die ethischen Überlegungen im Umgang mit geisteswissenschaftlichen Daten und konzentriert sich dabei auf den Schutz personenbezogener Daten, die Rechte an geistigem Eigentum und die ethischen Implikationen der Datenkategorisierung und -verarbeitung. Es wird betont, wie wichtig es ist, eine Einwilligung einzuholen, die Privatsphäre zu schützen, Urheberrechte zu respektieren und die Verzerrungen und Auswirkungen von Datenstrukturen und -analysen zu berücksichtigen. Die Lernenden werden verstehen, wie man Daten anonymisiert, Urheberrechte respektiert und ethische Grundsätze auf die Kategorisierung und Datenverarbeitung anwendet, um sicherzustellen, dass ihre Forschung verantwortungsvoll und ethisch korrekt durchgeführt wird.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Daten und Datenbanken, die von James Baille und Daniel Knox geschrieben und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurden.  Datenverwaltung und -speicherung: Die ordnungsgemäße langfristige Speicherung von Daten ist für die Nachhaltigkeit und Zugänglichkeit der Forschung in den Geistes- und Sozialwissenschaften entscheidend. Dieser Kurs führt Sie durch die Planung der Wiederverwendung von Daten, die Bewältigung technischer und ethischer Herausforderungen und die Gewährleistung eines verantwortungsvollen Datenmanagements. Lernen Sie, wie Sie Ihre Daten effektiv strukturieren, speichern und dokumentieren können, um zukünftige Forschung zu unterstützen und die Anforderungen des offenen Zugangs zu erfüllen.  Diese Ressource ist Teil einer Gruppe von Ressourcen zu Daten und Datenbanken, die von James Baille und Daniel Knox geschrieben und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurden.  Eine grundlegende Einführung in Geografische Informationssysteme: Die raumbezogene Arbeit in Geographischen Informationssystemen (GIS) umfasst zwei Haupttypen: Analyse und Visualisierung. Die Analyse umfasst Computertechniken zur Verarbeitung und Interpretation räumlicher Daten, während die Visualisierung diese Daten für den Menschen verständlich macht. In den meisten GIS-Projekten werden diese Aspekte miteinander kombiniert, um die Stärken beider Bereiche zu nutzen, und dieser Leitfaden soll diese Konzepte auch für GIS-Neulinge zugänglich machen.  Diese Ressource ist ein Wegweiser zu Geographischen Informationssystemen (GIS), der durch eine Zusammenarbeit mit Liam Downs-Tepper inspiriert und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurde. Schlagworte:Aufbereitung von DH-Kursen für Lehrende und Studierende; damit Vereinheitlichung des DH-Angebots und Nachnutzung; etwa Kurs 'Digitale Transformation der Handschriftenforschung', stark interdisziplinär ausgerichtete und von insgesamt vier verschiedenen Einrichtungen durchgeführte Lehrveranstaltung; sehr umfangreichen Unterlagen erlauben es, die LV in weiten Teilen nachzuvollziehen.   ",
    "url": "dhlehre.html"
  },
  {
    "id": "dhlehre_en",
    "title": "Teaching DH at the University of Vienna",
    "content": "Artificial Intelligence Prompt Engineering Text to Text: Enter the world of text-to-text AI with this resource on prompt engineering. Learn how to craft precise input prompts to guide AI in generating desired text outputs, enhancing applications in chatbots, content creation, and language translation. By mastering various techniques, you’ll improve the efficiency and accuracy of AI interactions, tailoring responses to meet specific needs in humanities research and beyond.  This resource is part of a group of resources on Artificial Intelligence by Emily Genatowski based on the course she developed and taught at The University of Vienna titled Artificial Intelligence and Large Language Models in Humanities Research.  Introduction to Advanced Image Generation Techniques:  Explore advanced AI image generation techniques in this resource, designed to help you work with AI tools efficiently and accurately. Learn how to use methods such as word weighting and narrative elements to bridge the connection between your vision and the AI's output. This guide will equip you with the skills to employ these techniques effectively, blending art, and technology to transform digital image creation.  This resource is part of a group of resources on Artificial Intelligence by Emily Genatowski based on the course she developed and taught at The University of Vienna titled Artificial Intelligence and Large Language Models in Humanities Research.  Artificial Intelligence Prompt Engineering Legal, Societal and Ethical Issues:  This resource introduces the ethical, societal, and legal complexities of Artificial Intelligence, focusing on the challenges posed by its development and implementation. It explores potential risks such as bias, privacy, autonomy, and job displacement, using case studies to highlight real-world issues. The resource aims to equip learners with critical thinking skills to evaluate AI's impact and navigate its ethical and legal implications responsibly.  This resource is part of a group of resources on Artificial Intelligence by Emily Genatowski based on the course she developed and taught at The University of Vienna titled Artificial Intelligence and Large Language Models in Humanities Research.  Applied Artificial Intelligence:  This resource explores the transformative impact of Artificial Intelligence across various sectors, including healthcare, finance, retail, manufacturing, and more. By examining the unique benefits, challenges, and future potential of AI, learners will gain insight into how AI is reshaping traditional practices and envision its role in the future. Upon completion, learners will be equipped to understand the current applications of AI, discuss its limitations, and predict its future uses in multiple fields.  This resource is part of a group of resources on Artificial Intelligence by Emily Genatowski based on the course she developed and taught at The University of Vienna titled Artificial Intelligence and Large Language Models in Humanities Research.  Prosopography: What is a Person?:  In this resource, the key concept is the prosopon, an invaluable tool in historical and literary studies that represents a collected literary depiction of a person. A prosopon includes all forms of information about an individual, gathered from various sources such as texts, records, and artifacts. By studying prosopons, we can piece together comprehensive portraits of individuals from the past, even if these portraits are sometimes fragmented or biased. This approach helps us understand the societal roles, personal relationships, and historical significance of individuals, providing a richer context of the past.  This resource is part of a group of resources on Prosopography written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski based on the course taught at The University of Vienna titled Prosopography and Social Network Analysis.  Prosopography: Identity: This resource covers the Theory of Identity in Prosopography, focusing on characteristics like roles, titles, ages, ethnicity, sexuality, gender, and religion. It highlights the complexities of these identities, which are fluid, multi-layered, and subject to change over time, emphasizing the need for a nuanced and flexible approach in historical research. The resource aims to equip learners with the ability to critically analyze historical sources and understand the dynamic nature of identity construction and representation.  This resource is part of a group of resources on Prosopography written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski based on the course taught at The University of Vienna titled Prosopography and Social Network Analysis.   Prosopography: Scoping a Database: This resource discusses the importance of defining the scope of a database project in the humanities and social sciences. It emphasizes the necessity of setting boundaries to ensure the project is manageable, aligns with research questions, and informs other researchers about the database's content. Learners will understand the significance of formal scoping, differentiate between source and model scoping, and learn the essential questions to ask when scoping a database.  This resource is part of a group of resources on Prosopography written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski based on the course taught at The University of Vienna titled Prosopography and Social Network Analysis.   Data and Databases: An Introduction: Databases are fundamental to modern information management, enabling the structured collection and analysis of data. This course bridges the gap for humanities and social science researchers, providing an overview of technical skills needed to query and create databases while addressing the unique challenges posed by humanities data. Learn to use databases effectively to enhance your research, from project planning and data storage to navigating ethical considerations.  This resource is part of a group of resources on Data and Databases written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna.   Databases: Source to Data: This resource discusses the unique characteristics and challenges of humanities and social scientific data, which differ significantly from scientific data. It highlights issues such as non-experimental nature, source dependency, high complexity, and variability in data quantity and consistency. The guide also covers the importance of understanding data capture processes, metadata, and the implications of how data is classified and structured for database creation in the humanities.  This resource is part of a group of resources on Data and Databases written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna.   Entity Relationship Data Model: In this resource, learners will understand the importance of defining entities—objects with distinct characteristics—within a given field. Learners will explore associations (relationships between entities), attributes (elementary data on entities), identifiers (unique attributes that distinguish entities), and cardinalities (measures of how entities relate to one another). By mastering these concepts, you can effectively model and manage data in various domains.  This resource is part of a group of resources on Data and Databases written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna.  Scoping a Database Project: This resource helps learners understand the importance of scoping prosopography projects, guiding you in forming a scope based on research questions and key factors. By clearly defining the scope, researchers can streamline efforts, focus on relevant data, and produce meaningful results. Learn to set effective boundaries, delineate clear project parameters, and ensure that research is both focused and comprehensive.  This resource is part of a group of resources on Data and Databases written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna.  Data Ethics:  This resource discusses the ethical considerations in handling humanities data, focusing on personal data protection, intellectual property rights, and the ethical implications of data categorization and processing. It emphasizes the importance of obtaining consent, ensuring privacy, respecting copyrights, and considering the biases and impacts of data structures and analyses. Learners will understand how to anonymize data, respect copyrights, and apply ethical principles to categorization and data processing, ensuring their research is conducted responsibly and ethically.  This resource is part of a group of resources on Data and Databases written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna.  Data Management and Storage: Proper long-term data storage is crucial for the sustainability and accessibility of research in humanities and social sciences. This course guides you through planning for data re-use, addressing technical and ethical challenges, and ensuring responsible data management. Learn how to structure, store, and document your data effectively to support future research and comply with open access requirements.  This resource is part of a group of resources on Data and Databases written by James Baille and Daniel Knox and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna.  A Basic Introduction to Geographic Information Systems: Spatial work in Geographic Information Systems (GIS) encompasses two main types: analysis and visualization. Analysis involves computational techniques to process and interpret spatial data, while visualization makes this data comprehensible to people. Most GIS projects blend these aspects to utilize the strengths of both, and this guide aims to make these concepts accessible even to those new to GIS.  This resource is a pathfinder on Geographic Information Systems (GIS) inspired by a collaboration with Liam Downs-Tepper and assembled onto Dariah Campus by Emily Genatowski of The University of Vienna. terms:Preparation of DH courses for lecturers and students; thus standardization of the DH offer and subsequent use; for example, course 'Digital Transformation of Manuscript Research', strongly interdisciplinary course conducted by a total of four different institutions; very extensive documents allow the course to be followed in large parts.   ",
    "url": "dhlehre.html"
  },
  {
    "id": "öawtraining",
    "title": "Training an der Österreichischen Akademie der Wissenschaften",
    "content": "Das Teilprojekt bzw. Arbeitspaket “Training” am Austrian Centre for Digital Humanities and Cultural Heritage (ACDH-CH) konzentriert sich auf die Entwicklung von unterstützenden didaktischen Konzepten und Schulungsmaterialien, um zum einen Grundlagen der Digital Humanities zu vermitteln, aber andererseits auch die am Institut entwickelten Tools, Services und Methoden einem breiten Zielpublikum bestehend aus Forschenden, Studierenden sowie einer interessierten Öffentlichkeit näherzubringen.  Das ACDH-CH kann dafür auf die Expertise und Erfahrung bei Durchführung und Einsatz der am Institut entwickelten und etablierten unterschiedlichen ormate für Training und Wissenstransfer zurückgreifen: Tool Galleries, ACDH-CH Lectures, Internships, sowie die Bereitstellung der Trainingsmaterialien über die HowTo Plattform.  Hervorzuheben ist auch der von CLARIAH-AT initiierte Cultural Hackathon “ExploreSalon”, welcher im Mai 2023 in Kooperation mit der Österreichischen Nationalbibliothek stattgefunden hat.  Die genannten Aktivitäten sind akkordiert mit verwandten Initiativen zu Training und Wissenstransfer des CLARIAH-AT Konsortiums, der Forschungsinfrastrukturen CLARIN und DARIAH, sowie im Rahmen des Ausbaus von EOSC (European Open Science Cloud).   Cultural Hackathon “ExploreSalon 2023: Unveil Hidden Stories from the Past”  “When people interact, they leave traces: uncountable letters, diaries, chronicles, plaques, and other written records have preserved memories about people – long before the rise of smartphones and social media. For the duration of one week the ExploreSalon at the ACDH-CH in Vienna offers a space to explore those digitized memories, seek hidden stories, discuss and share ideas as well as findings.”  Im Mai 2023 wurde im Rahmen von CLARIAH-AT und DiTAH am ACDH-CH ein einwöchiger Kulturhackathon – der “ExploreSalon” – in Kooperation mit der ÖNB veranstaltet. Der ExploreSalon verfolgte die Idee, Menschen mit unterschiedlichen Hintergründen zusammenzubringen und ihnen die Möglichkeit zu geben, innovative Wege des datenbasierten Storytellings zu entdecken - Geschichten, die in den Daten verborgen sind, zu erforschen, Ideen zu präsentieren und Ergebnisse zu teilen.  Das Konzept des ExploreSalons basiert auf kulturellen Hackathons wie „OpenGLAM.at“, „Coding Da Vinci“ und „Coding Duerer“. Im Gegensatz zu einem traditionellen „Hackathon“, der sich vor allem an Menschen mit technischem Hintergrund richtet, zielt ein kultureller Hackathon darauf ab, alle Arten von kreativen Köpfen mit unterschiedlichen Fähigkeiten und Fachkenntnissen aus den Bereichen (digitale) Geisteswissenschaften und Kulturerbe sowie GLAM-Einrichtungen (Galerien, Bibliotheken, Archive und Museen) zusammenzubringen.  Der ExploreSalon verfolgt einen zweckorientierten Ansatz und zielt darauf ab, die Community of Practice in die Lage zu versetzen, ihren eigenen Arbeitsprozess zu steuern, indem sie sich von starren Rahmenbedingungen und Zeitplänen löst. Kommunikation/Dialog auf Augenhöhe und Werte wie Transparenz, offenes Wissen und partizipative Führung stehen im Vordergrund und nicht eine Reihe spezifischer Methoden.   Lectures  Im Rahmen der ACDH-CH Lectures lädt das Institut “internationale Expert*innen aus dem Bereich der Digital Humanities ein, ihre Forschung zu präsentieren. In den Lectures gewähren sie Einblicke in die Bedeutung digitaler Technologien für ihre Arbeit und diskutieren die Rolle der Digital Humanities für die Zukunft. Die ACDH-CH Lectures stehen allen Interessierten offen.” Während der Laufzeit des DiTAH-Projektes wurden 16 Lectures in Kooperation mit CLARIAH-AT, CLARIN, DARIAH-EU, Universität Wien, Universität für Weiterbildung Krems und dem Österreichischen Archäologischen Institut an der ÖAW veranstaltet. Schlagworte:interaktives Lernmaterial, praktische HowTo-Artikel und Best-Practice-Beispiele zu allgemeinen und spezifischen Themen, Methoden und Infrastrukturen der Digital Humanities; diese Lernressourcen vermitteln auf einfache Art und Weise und ohne notwendiges Vorwissen Wissen aus der DH an Einsteiger und Fortgeschrittene in den DH; Die Tool Gallery sind ein dreimal im Jahr stattfindender Workshop, in dem in Präsenz die Anwendung digitaler Methoden in den Geisteswissenschaften vermitteln; Sie sind eine Schnittstelle zwischen Theorie und Praxis und richten sich an Geisteswissenschaftler:innen, die sich mit computerbasierten Methoden in ihrer Forschung beschäftigen wollen.Dreimal im Jahr präsentieren internationale Expert:innen aus dem Bereich der Digital Humanities am ACDH-CH ihre Forschung und geben Einblicke in die Bedeutung digitaler Technologien. Die Vortragsreihe richtet sich an interessierte Forscher:innen aus den Geisteswissenschaften allgemein.",
    "url": "training.html"
  },
  {
    "id": "fercan",
    "title": "Die keltischen Götternamen der germanischen Provinzen (FERCAN) - Patrimonium-Editor",
    "content": "Das Projekt „Die keltischen Götternamen in den lateinischen Inschriften im linksrheinischen Militärgebiet der Germania Superior. Religiöse Erscheinungsformen in einer Kulturkontaktzone.“ erfasst in einer digitalen Edition römische Weihinschriften mit keltischen Götternamen. Bei dieser Edition werden die in den Inschriften enthaltenen Votivformulare und Götternamen aus sprachwissenschaftlicher, epigraphisch-historischer und ikonographischer Sicht untersucht und klassifiziert. Die angewendete Methodik wurde im Vorgängerprojekt „Die keltischen Götternamen in den Inschriften der römischen Provinz Germania Inferior. Eine Fallstudie zu Religion im Kontext von Kulturkontakt und Kulturtransfer.“ entwickelt und weiter verfeinert. Beide Projekte stehen inhaltlich in Beziehung zum Corpus F.E.R.C.A.N. (Fontes epigraphici religionum Celticarum antiquarum), welches das Ziel verfolgt in den einzelnen Provinzen des römischen Reiches, all jene Inschriften zu edieren, die einen möglichen keltischsprachigen Hintergrund haben. Die insgesamt 589 Einzelbeiträge dieser beiden Projekte sind für die Öffentlichkeit zugänglich auf der Datenbank „Die keltischen Götternamen der germanischen Provinzen“ publiziert und können außerdem per pdf-Warenkorb in Auswahl heruntergeladen werden. Nach den Erfahrungen bei der Vorbereitung der Daten für die Onlinepublikation im Germania Inferior-Projekt, wurde gemeinsam mit dem Zentrum für Informationsmodellierung eine Eingabemaske für die Datenerfassung sowie leichtere Übertragung der Daten in ein Webseitenformat kreiert. Das Ergebnis ist die Anpassung des Patrimonium-Editors, der von der Universität von Bordeaux für die Erfassung epigraphischen Materials geschaffen wurde, an die Bedürfnisse des Projektes durch das Uni Graz start-up DH-Craft. Die Dokumentation des Überarbeitungsprozesses, sowie unsere Erfahrungen in der Praxisanwendung haben wir zum Zwecke der Erfahrungsweitergabe auf dem „Social Sciences & Humanities Open Marketplace“ veröffentlicht. Schlagworte:Inschriftenedition, keltische Götternamen, umfangreiche Beschreibung der einzelnen Datensätze, Langzeitspeicherung in Repositorium, digitale Edition, digitale, interaktive Landkarte inkl. Verknüpfung zu Datensätzen der Edition; gesamte Edition mit bestehenden Datenbanken verknüpft; ausführliche Dokumentation und allgemein gehaltene Anleitung zur Nutzung eines bestehenden Inschriften-Editors zur Sammlung, Verwaltung und wissenschaftlichen Analyse epigraphischer Daten; ist für Softwareentwickler wie für Nutzer des Programms gleichermaßen;  ",
    "url": "fercan.html"
  },
  {
    "id": "dhplus",
    "title": "Digital Humanities an der PLUS",
    "content": "In Abstimmung mit den Projekten DiTAH und DHInfra.at wird an der PLUS ein DH Helpdesk als zentraler Service für und eine aktive Schnittstelle zu Forschenden, Lehrenden und verschiedenen Fachbereichen der Universität sowie zu externen Partner*innen, DH-Akteur*innen und Dienstleister*innen aufgebaut. Seine Arbeitsfelder liegen im Bereich der Koordination, Beratung und Kooperation. Seine Aufgaben umfassen: das breite, interdisziplinäre DH-Angebot der PLUS intern und extern sichtbar zu machen, die DH-Aktivitäten intern und extern zu vernetzen sowie Synergieeffekte zu bundesweiten oder österreichweiten Aktivitäten und Initiativen zu nutzen und zu schaffen, laufende und neue DH-Forschungsprojekte an der PLUS zu beraten und zu begleiten, in der Lehre einen aktiven Wissenstransfer zu betreiben sowie strategisch innerhalb der PLUS und im Verbund mit nationalen Akteur:innen an den Themen Digitalisierung und Forschungsdatenmanagement mitzuarbeiten. Mini-Projekt „Annotationen im Semantic Web“ Mit den Datensammlungen des Instituts für Realienkunde des Mittelalters und der Frühen Neuzeit (IMAREAL) und der Mittelhochdeutschen Begriffsdatenbank (MHDBDB) verfügt das Interdisziplinäre Zentrum für Mittelalter und Frühneuzeit (IZMF) über große Datenpools, die über viele Jahre aufgebaut wurden und sich durch umfangreiche semantische Annotationen für sprachwissenschaftliche, historische, kunsthistorische und kulturwissenschaftliche Fragestellungen auszeichnen. Die Datenarchitekturen dieser Bestände und ihre Modellierung im RDF-Format wurden im Rahmen von DiTAH für übergreifende Abfragen im Semantic Web vorbereitet, evaluiert und dokumentiert. Die gewonnenen Erkenntnisse wurden über das neu eingerichtete Wissenschaftsblog „Digital Humanities an der PLUS Salzburg“ mit der Community geteilt. Schlagworte: Schaffung eines DH-Helpdesks; Schnittstelle zwischen Forschenden, Lehrenden und Fachbereichen sowie externen Partner:innen; Dh-Akteur:innen und Dienstleister:innen; DH-Angebot der PLUS sichtbar machen, DH-Aktivitäten intern und extern zu vernetzen; DH-Projekte beraten und zu begleiten, Ständig erweitern sich die Methoden und Fragestellungen in den Digital Humanities. im Rahmen einer Ringvorlesung werden in insgesamt 15  online verfügbaren Vorlesungen innovative und rezente Methoden einem interessierten Publikum vorgestellt und ihre Anwendung im Forschungsalltag präsentiert. Das Spektrum reicht vom EInsatz sog. Künstlicher Intelligenz, Natural Language Processing, Distant Viewing, DNA-Sequenzierung und Netzwerkanalysen, dem Arbeiten mit digitalen 3D-Modellen und GIS-basierten Analysen, Digitales Editieren und Annotieren sowie Ansätze aus den Game Studies und den Citizen Sciences. ",
    "url": "dhplus.html"
  },
  {
    "id": "habsburg",
    "title": "Digitale Habsburg Platform / DH an der Universität Wien ",
    "content": "Die Idee einer Digital Habsburg Platform kommt von der langfristigen Notwendigkeit, Datenressourcen zu einer bestimmten Region und Epoche - hier Zentraleuropa zwischen Hochmittelalter und Moderne - zusammenzuführen und somit großangelegter datenanalytischer Forschung zugänglich zu machen. Ursprünglich war die DHP konzipiert als Serie dokumentierter Workshops, in denen einschlägige Datenressourcen zusammengebracht werden sollten. So sollte die Grundlage und zugleich die Plattform für eine Zurverfügungstellung geschaffen werden, die Überblick vermittelt und Interoperabilität ermöglicht. Es hat sich ergeben, dass die Schaffung der epistemischen, konzeptionellen und institutionellen Voraussetzungen für einen solchen Prozess länger dauert als angenommen. Daher hat sich angeboten, das Projekt in einzelnen kleineren Schritten in Angriff zu nehmen, die sich aber langfristig weiterhin an der ursprünglichen Idee orientieren. Einige dieser Schritte betreffen konkrete Daten, andere bemühen sich gezielt um die Schaffung von Überblick. Die einzelnen Komponenten sind die Dokumentation von zwei Workshops, die das ursprüngliche Konzept anhand von prosopographischen Projekten umsetzen: Beispieldatensätze zu Korrespondenz und Nachlass der Brüder Pez und ein seit Anfang 2022 regelmäßig auf Deutsch und Englisch erscheinender Digital-Humanities-Newsletter, der aus der Perspektive der Historisch-Kulturwissenschaftlichen Fakultät der Universität Wien das DH-Geschehen in Österreich und international dokumentiert: ein strukturierter Überblick im Rahmen der Clio-Guides über historische DH-Ressourcen in und zu Österreich, ergänzt um eine Geschichte der DH in Österreich  eine COST-Action, in deren Rahmen zwischen 2025 und 2029 weiter an dem veranschlagten Ziel gearbeitet wird. Schlagworte: Digital Habsburg Platform (DHP), Datenanalytische Forschung, Zentraleuropa, Hochmittelalter bis Moderne, Datenressourcen, Interoperabilität, Workshops, Prosopographische Projekte, Brüder Pez, Korrespondenz und Nachlass, Digital Humanities Newsletter, Historisch-Kulturwissenschaftliche Fakultät, Universität Wien, DH-Geschehen in Österreich, Clio-Guides, Historische DH-Ressourcen, Geschichte der Digital Humanities (DH) in Österreich, COST-Action, Epistemische Voraussetzungen, Konzeptionelle Voraussetzungen, Institutionelle Voraussetzungen",
    "url": "habsburg.html"
  },
  {
    "id": "phaidra",
    "title": "Phaidra - mūsēum: an easy to use proxy server, orchestrator and serverless runtime for your web applications",
    "content": "Diese Ressource ist ein Wegweiser zu geografischen Informationssystemen (GIS), der durch eine Zusammenarbeit mit Liam Downs-Tepper inspiriert und von Emily Genatowski von der Universität Wien auf Dariah Campus zusammengestellt wurde. mūsēum speichert Informationen zu laufenden Applikationen via etcd. Bei einer Anfrage kontrolliert mūsēum, ob die Anwendung im Docker Swarm läuft; wenn ja, wird die Anfrage weitergeleitet. Wenn nicht, wird ein Ladebildschirm erzeugt, um die Applikation zu starten.  Schlagworte: museum, webanwendungen, innerhalb kurzer zeit, keine langfristigen ansätze; museum archiviert und stellt zur verfügung",
    "url": "phaidra.html"
  },
  {
    "id": "eosc",
    "title": "European Open Science Cloud (EOSC)",
    "content": "“The ambition of the European Open Science Cloud (EOSC) is to develop ‘Web of FAIR Data and services’ for science in Europe. EOSC will be a multi-disciplinary environment where researchers can publish, find and re-use data, tools and services, enabling them to better conduct their work.” Das Teilprojekt bzw. Arbeitspaket “EOSC” am ACDH-CH zielt darauf ab, die Integration der Initiative EOSC (European Open Science Cloud) und der österreichischen DH-Forschung voranzutreiben, dabei das Angebot und die Ergebnisse von EOSC in der österreichischen DH-Forschungslandschaft bestmöglich zu nutzen, sowie die Anknüpfung, Vernetzung und den Austausch mit der Vielzahl an beteiligten Akteuren im europäischen Raum zu fördern. Auf technischer Ebene bedeutet Integration in dieser Phase insbesondere die Dissemination österreichischer Forschungsoutputs durch zentrale europäische Metadaten-Kataloge, allen voran OpenAIRE (Open Access Infrastructure for Research in Europe), um eine bessere Sicht- und Durchsuchbarkeit dieser Daten sicherzustellen. Diese ist eine Voraussetzung für das Teilen und die Nutzung von Daten und Services im gesamten europäischen Forschungsraum. Zu diesem Zweck wurden die Repositories ARCHE und GAMS mit OpenAIRE integriert (on-boarding), d.h. ihre Metadaten werden geharvested und können so als Teil des gesamten OpenAIRE Research Graph exploriert/erschlossen werden. Zusätzlich wurden sie registriert als Teil des DARIAH Community Gateway’s, so dass die Ressourcen aus diesen Repositorien als Teil von DARIAH Resources gelten. Dank seines Engagements in den Projekten EOSC Future und SSHOC konnte sich das ACDH-CH Team ideal positionieren, um die aktuellen Entwicklungen auf europäischer Ebene zu beobachten und auf nationaler und institutioneller Ebene zu vermitteln, bzw. einzusetzen. Aktueller Stand: Die Situation bzgl. weiterer Entwicklung von EOSC ist nach dem Ende des EOSC-Future Projektes sehr volatil. Im Rahmen von Procurements wurden neue Betreiber für den Betrieb von zentralen Komponenten der EOSC-Infrastruktur ausgelobt, derzeit gibt es jedoch keine stabilen zentralen Services, bzw. klare Vorgaben zur Integration von lokalen, thematischen oder nationalen Services und Strukturen. Im Herbst 2024 soll im Rahmen des EOSC Symposiums die neue EOSC EU Node vorgestellt werden, welche zentrale Services bereitstellen wird. In enger Absprache mit DARIAH, liegt daher der Fokus auf Integration von Services mit OpenAIRE und SSH Open Marketplace, in der Annahme, dass diese Systeme jedenfalls eine Rolle, in der sich derzeit neugestaltenden technischen Struktur von EOSC spielen werden. Das DiTAH-Teilprojekt “Repositorien-Discovery” hat sich in diesem Zusammenhang intensiv mit OpenAIRE und den damit verbundenen Möglichkeiten auseinandergesetzt. Eine wichtige Rolle werden in diesem Kontext die neuen Infrastruktur-Projekte: ATRIUM, OSCARS, OS Trails, ECHOES, in denen DARIAH und tlw. auch das ACDH-CH involviert sind. Der veröffentlichte Bericht vom Oktober 2023 informiert über die Entwicklungen bei EOSC auf europäischer, sowie nationaler Ebene. ACDH-CH als affiliated entity von DARIAH im EOSC Future Projekt, war auch am Deliverables D6.2b zu Workflows developed from the Moderation Process to Onboard External Providers beteiligt. Bis zum Ende des Projektes soll des Weiteren ein White Paper erstellt werden, welches die neuesten Entwicklungen sowie die aktuelle Situation zusammenfasst und Vorschläge für die Integration von DH-Aktivitäten in Österreich mit EOSC liefert. Schlagworte:",
    "url": "eosc.html"
  },
  {
    "id": "repositorydiscovery",
    "title": "Repository-Discovery",
    "content": "Das Teilprojekt Repositorien Discovery wurde in enger Verzahnung mit dem Teilprojekt EOSC durchgeführt und zielte auf eine bessere Auffindbarkeit geistes- und kulturwissenschaftlicher Forschungsdaten und -ressourcen in den österreichischen Repositorien ab. Zu diesem Zweck war der Aufbau eines österreichweiten Verbundes von Repositorien wie ARCHE (ACDH-CH), GAMS (Universität Graz, ZIM-ACDH) und PHAIDRA (Universität Wien) geplant, um den Wissensaustausch zu verstärken und die bestehenden Repositorien-Lösungen im Hinblick auf APIs, Metadatenschemata und Richtlinien zu harmonisieren. Weiters wurde auch eine verstärkte Zusammenarbeit zwischen den Digital Humanities und Cultural Heritage Institutionen (GLAM) nach dem Vorbild der ÖNB Library Labs angestrebt, um die Sichtbarkeit und Nutzbarkeit von Cultural Heritage Daten und Objekten zu erhöhen. Die ursprünglich anvisierte Idee eines eigenen österreichischen Katalogs für DH-Forschungsdaten (dha-catalogue basierend auf der dha-ontology) wurde zugunsten einer Integration mit etablierten Lösungen auf europäischer Ebene aufgegeben, allen voran OpenAIRE (Open Access Infrastructure for Research in Europe) und SSH Open Marketplace. Dies ermöglicht eine deutlich höhere Reichweite für die Dissemination der Forschungsoutputs und minimiert den Aufwand für die Entwicklung und Wartung von eigenen Komponenten. Im Rahmen des Projekts konnten die Repositorien ARCHE und GAMS in OpenAIRE integriert werden (PHAIDRA war bereits integriert), sodass neue Ressourcen aus diesen Repositorien automatisch aggregiert werden. Um einen Überblick über die Gesamtheit der österreichischen DH-Ressourcen hinsichtlich ihrer Repräsentation in OpenAIRE zu gewinnen, wurde eine umfassende Analyse/kritische Auswertung durchgeführt. Diese hat eine sehr lückenhafte Abdeckung dieser Ressourcen aufgezeigt und weist auf einen erheblichen Bedarf bei der Kuratierung, Harmonisierung und Integration von Metadaten hin. Bei solchen Maßnahmen zur Integration, Aggregation und Harmonisierung von Metadaten stellen Controlled Vocabularies einen notwendigen Baustein für die semantische Interoperabilität dar. In Vorbereitung auf eine zukünftige Harmonisierung wurde daher eine umfassende Analyse der sich in Verwendung befindlichen Vocabularies/Keywords der Repositorien ARCHE und GAMS sowie DARIAHCampus, SSHOC, TaDiRAH, der DHA Taxonomy, der DHA Website und anderen Initiativen durchgeführt. Durch seine Beteiligung an Infrastrukturprojekten wie SSHOC, konnte das ACDH-CH Team in diesem Zusammenhang auch auf bereits gewonnene Expertise bei der Entwicklung kontrollierter Vokabularien sowie auf jene, im Rahmen des SSHOC Projektes entwickelten, Ressourcen wie beispielsweise die Plattform SSH Vocab Commons, zurückgreifen. Im Rahmen des Teilprojektes hat sich schließlich auch die Arbeitsgruppe DHA Commons herauskristallisiert, deren Hauptaufgabe die Konsolidierung österreichischer Zotero-Libraries zum Thema DH mit Augenmerk auf eine Harmonisierung der verwendeten Tags war. Schlagworte:",
    "url": "repository.html"
  },
  {
    "id": "LudwigFicker",
    "title": "Ludwig von Ficker Edition",
    "content": "Das Projekt hat es sich zum Ziel gesetzt, eine kommentierte Online-Edition des Gesamtbriefwechsels von Ludwig von Ficker zu erstellen und frei zugänglich zu machen. Ludwig von Ficker (1880-1967) war Publizist und zählt - nicht zuletzt durch die Gründung der Zeitschrift \"Der Brenner\" - zu den bedeutendsten Kulturvermittlern Österreichs in der ersten Hälfte des 20. Jahrhunderts. Die umfangreiche Korrespondenz von Fickers zählt zu den Kernbeständen des Forschungsinstituts Brenner-Archiv der Universität Innsbruck, weshalb die Texterschließung und Publikation des Gesamtbriefwechsels ein lange gehegtes Desiderat war. Die Edition richtet sich gleichermaßen an die Fachwelt und interessierte Laien, weshalb philologische Sorgfalt und Benutzer*innenfreundlichkeit gleichermaßen gewährleistet sein mussten. In der aktuellen Version sind etwa 5000 Briefe und Gegenbriefe aus der Korrespondenz von Ludwig von Ficker zugänglich und werden laufend ergänzt. Neben der Transkription des Brieftextes wurden Personen- und Ortsnamen, Werk- und Aufsatztitel annotiert und erklärungsbedürftige Textstellen durch Einstellenkommentare erläutert. Die Edition verfügt über eine Registersuche mit derzeit mehr als 6400 Einträgen, die - wo diese vorhanden sind - mit den entsprechenden Einträgen in der GND verknüpft wurden. Die Briefe werden im Word-Format von den Editor:innen bearbeitet und dann nach XML-TEI konvertiert. Die XML-TEI Daten sind die Grundlage sowohl für die HTML-Repräsentation der Onlineedition als auch für andere Funktionen (z.B. für die Erstellung der Register oder für die Such-Funktion). Schlagworte:Der über 13.000 Schriftstücke umfassende Briefwechsel des Publizisten Ludwig von Ficker (1880-1967) wurde in diesem Projekt transkribiert, annotiert und kommentiert. Damit liegt ein umfangreiches Korpus regionalhistorisch relevanter Briefe inkl. Orts- und Namensregister vor, das sich gezielt durchsuchen lässt.",
    "url": "ficker.html"
  },
  {
    "id": "fotodb",
    "title": "Foto-Datenbank",
    "content": "Mit dem Teilprojekt Foto-Datenbank wurde das Ziel verfolgt, eine geeignete und leicht adaptierbare Lösung für die Speicherung und Zur-Verfügungstellung von Bildern/Fotos zu erarbeiten. Besonders für Archive und wissenschaftliche Sammlungen ist eine OAI-PMH-Schnittstelle von Bedeutung, die ein Metadata-Harvesting durch Institutionen wie etwa die Europeana ermöglichen. Als Grundlage wurden hier OmekaS ausgewählt. OmekaS ist ein quelloffenes Sammlungsverwaltungssystem, das sich vor allem dadurch auszeichnet, dass es den Museen und Archiven einerseits erlaubt, virtuelle Ausstellungen zu gestalten, und andererseits diese Daten auch mit eigenen Ontologien zu verzeichnen. Die quelloffene Software bietet außerdem den Vorteil, dass sie von einer breiten Comunitiy transparent entwickelt wird, was die Installation und Wartung erleichtert und die Zukunftsfähigkeit garantiert. Für das OAI-PMH Schnittstelle wurde ein eigenes Modul in Java erstellt, das es erlaubt, die Daten abzugreifen und per XSLT in beliebiges Datenformat transformeirt. Für die Fotodatenbank wurden Bilder aus dem Bestand von Clemens Holzmeister ausgewählt, aber auch für ein Projekt aus dem Förderprogramm 'Kulturerbe digital' zum Nachlass Schrödinger. Schlagworte:Digitalisierung, immer mehr Digitalisate zugänglich; um diese wissenschaftlich zu verwerten sind jedoch metadaten und damit semantische informationen darüber notwendig; diese metadaten aber oft nicht vorhanden; im teilprojekt 'fotodatenbank' wird eine formale repräsentation zu diesen digitalisaten erstellt (Metadaten basierend auf einer DHA-Ontologie), die diese wissenschaftlich bearbeitbar machen",
    "url": "fotodatenbank.html"
  },
  {
    "id": "holzmeister",
    "title": "Digitales Werkverzeichnis Clemens Holzmeister",
    "content": "Das Teilprojekt 'Digitales Werkverzeichnis Clemens Holzmeister' wurde vom Forschungsinstitut Brenner-Archiv in Zusammenarbeit mit dem Archiv für Bau.Kunst.Geschichte durchgeführt. Grundlage dafür war die Aufarbeitung des umfangreichen Nachlasses des österreichischen Architekten Clemens Holzmeister (1886-1983), der 2011 aus Privatbesitz in den Bestand des Archivs für Bau.Kunst.Geschichte der Universität Innsbruck übergegangen ist. Auf Grundlage des Bestandes wurde ein aktualisiertes Werkverzeichnis erstellt, welches einen Überblick über Holzmeisters Schaffen bietet. Die Metadaten zu den von Holzmeister geplanten Bauten wurden zentral gesammelt, aktualisiert und vereinheitlicht. Auf dieser Grundlage wurde u. a. eine interaktive Karte erstellt, auf der die Standorte der Werke eingesehen werden können. Von besonderer Relevanz ist die durch das digitale Werkverzeichnis ermöglichte Verlinkung zwischen Werk- und Fotosammlung sowie des dazugehörigen Pressespiegels, der die zeitgenössische Rezeption der Bauten dokumentiert. Die Daten werden über eine eigens erstellte Homepage zugänglich gemacht und stehen für weitere Forschungsprojekte zur Verfügung. Die hierfür eingesetzten technischen Lösungen können als Blaupause für ähnlich geartete Projekte verwendet werden. Schlagworte:Fotografien, Pläne, Zeichnungen aller von Clemens Holzmeister entworfenen Bauten; dazu umfangreiche Erfassung aller bekannten Ereignisse (weitere Entwürfe, Spatenstich, Grundsteinlegung, Erweiterungen, Umbauten, etc.); es ist einer der ersten Versuche, einen Architekturnachlass digital zu erfassen; darüber hinaus Verknüpfung seiner Werke mit bereits vorhanden digitalen Beständen von Holzmeister wie zu den rund 7.000 Zeichnungen und Plänen, seine rund 50.000 Seiten Korrespondenz, die ca. 7.000 Zeitungsartikel sowie zu den Einträgen in seinen Arbeits- und Taschenkalendern; zusätzlich werden alle Bauten und Projekte geolokalisiert; Erstellung eines Web-Interface",
    "url": "holzmeister.html"
  },
  {
    "id": "rnab",
    "title": "Datenverwaltung für RNAB-konforme Metadaten - RNABle",
    "content": "Im Teilprojekt RNABle wurde eine praxistaugliche Möglichkeit der Datenverwaltung für RNAB-konforme Metadaten erarbeitet. Die Ressourcenerschließung mit Normdaten in Archiven und Bibliotheken (RNAB) hat sich als Standard in Literaturarchiven etabliert und soll es auch nicht bibliothekarisch oder archivarisch ausgebildeten Bearbeiter*innen ermöglichen, Datensätze zu unterschiedlichen Ressourcen und Beständen zu erzeugen. Um dies weiter zu erleichtern und eine größtmögliche Einheitlichkeit in den Daten zu schaffen, strebt das Projekt RNABle an, ein Tool zu erstellen, dass die korrekte Anwendung der RNAB gewährleistet und erleichtert. Um diese Ziele zu erreichen, erwies sich OmekaS als geeignete Basis. OmekaS ist ein Datenverwaltungs-System, das speziell für die Erfassung von musealen Gegenständen entwickelt worden ist. Neben der Quelloffenheit zeichnet sich OmekaS auch dadurch aus, dass es mit unterschiedlichen Verzeichnungsstandards (Ontologien) arbeiten kann und -- per spezielle Module -- unterschiedliche Normdaten direkt anbindet. Diese Möglichkeit erlaubt es dem Projekt, eine auf RNAB zugeschnittene Verzeichnung -- mit der Verwendung von Normdaten aus GND -- zu verwirklichen. In Zusammenarbeit von Informatiker:innen und Archivar:innen wird ein Verzeichnungs-Schema in Protégé (als OWL-Datei) erstellt, welche Daten zu den Objekten (Items) in RNAB konformen Art und Weise organisiert. Im Moment wird ein Projekt aus dem Förderprogramm 'Kulturerbe digital' mithilfe RNABle finalisiert. Schlagworte: Nachlass, Datenverwaltung, RNAB-konforme Metadaten, Ressourcenerschließung mit Normdaten, Archive, Bibliotheken, Literaturarchive, Datensätze, Einheitlichkeit in Daten, Tool für RNAB Anwendung, OmekaS, Datenverwaltungs-System, Museale Gegenstände, Quelloffenheit, Verzeichnungsstandards (Ontologien), Normdatendirektanbindung, Gemeinsame Normdatei (GND), Verzeichnungsschema, Informatikerinnen und Archivarinnen, Protégé (OWL-Datei), Kulturerbe digital (Förderprogramm)",
    "url": "rnab.html"
  },
  {
    "id": "annolyzer",
    "title": "Annolyzer",
    "content": "Mit dem Annolyzer ist es möglich eine detaillierte und tiefgehende Recherche in ausgewählten Zeitungsbeständen der Österreichischen Nationalbibliothek zu machen. Die über Annolyzer zur Verfügung gestellten Daten haben eine verbesserte OCR, die Strukturinformationen bis auf Artikelebene abbilden kann. Daher ist es möglich gezielt in Zeitungsartikeln zu suchen und eigene Forschungskorpora zusammenzustellen. Unterstützt werden Forscher*innen durch eine erweiterte Suche, annotierte Entitäten (Personen, Orte, Organisationen) und umfangreiche statistische Auswertungen und Visualisierungen. Außerdem haben Benutzer*innen die Möglichkeit die Forschungsdaten zu exportieren und mit anderen Tools weiteren Analysen zu unterziehen. Ausgewählte Auswertungen können auch direkt in Annolyzer auf ein Datenset angewendet werden. Annolyzer basiert auf einer Software, die ursprünglich für das NewsEye-Projekt entwickelt wurde und wurde für den Einsatz an der Österreichischen Nationalbibliothek adaptiert. Schlagworte:",
    "url": "onbkulturerbe.html"
  },
  {
    "id": "redesignonblabs",
    "title": "Redesign Datasets ÖNB Labs",
    "content": "Redesign Datasets ÖNB Labs Die ÖNB Labs sehen sich als zentraler Einstiegspunkt für die computerunterstützte Arbeit mit Daten der Österreichischen Nationalbibliothek. Für ihre User stellen die ÖNB Labs ausgewählte Datensets inklusive Metadaten zur Verfügung und ermöglichen so eine kreative und künstlerische Nutzung der Daten. Diese Art der Zurverfügungstellung ist essenziell für beispielsweise Fragestellungen der Digitalen Geisteswissenschaften. Um den Anforderungen der Nutzer*innen gerecht werden zu können, ist das Angebot der Datensets einem umfangreichen Redesign unterzogen worden. In Interviews mit Usern wurden dabei die Use Cases abgesteckt und die Anforderungen gesammelt. In einem nächsten Schritt wurden in Design Sprints die Neugestaltung entwickelt, umgesetzt und dann in Tests mit Forscher*innen aus unterschiedlichen Forschungsfeldern evaluiert. Die wesentlichsten Änderungen sind eine neue übersichtliche und einheitliche Gliederung der Datensets (Info, Reuse, Preview, Data) mit Farbcodierung, einheitliche Angaben zur Rechtekennzeichnung und Nutzung der Daten und ein Daten-Sample zu jedem Datenset. Schlagworte:",
    "url": "onbkulturerbe.html"
  },
  {
    "id": "postkarten",
    "title": "Postkarten Kolorierung",
    "content": "Das Datenset der historischen Postkarten an der Österreichischen Nationalbibliothek umfasst circa 35.000 einzelne Postkarten aus der ganzen Welt mit unterschiedlichsten Motiven und Entstehungszeitpunkten. Circa 1/5 der Karten in der Collection sind auch farbig. Innerhalb des Projekts wurde mit Machine Learning eine Möglichkeit geschaffen, damit auch der schwarz-weiße Teil des Bestands in Farbe dargestellt werden kann. Dabei wurden ausführliche Anleitungen zur Kolorierung von Scans in schwarz-weiß erstellt, wo zwei unterschiedliche Machine Learning-Modelle verwendet werden. Einerseits wurde eine Pipeline umgesetzt, um die Daten mit einem bereits bestehenden externen Modell zu kolorieren und andererseits wurde mit transfer learning basierend auf dem farbigen Teil der Collection ein eigenes spezielles Modell angelernt und veröffentlicht. Schlagworte:",
    "url": "onbkulturerbe.html"
  },
  {
    "id": "pasetti",
    "title": "Pasetti Karte Digital",
    "content": "Die unter der Bezeichnung Pasetti-Karte bekannte Donau-Karte ist eine kartografische “Bestandsaufnahme” des Donauflusses samt Uferlandschaft vor den eingreifenden Donauregulierungen der zweiten Hälfte des 19. Jahrhunderts. Die Karte zeigt den Fluss der Donau von der deutsch-österreichischen Grenze bis zum Eisernen Tor in einem Maßstab von 1:28.800 basierend auf der Franziszeischen Landesaufnahme und Stromaufnahmen aus der Zeit vor 1830. Diese imposante Karte wurde an der Österreichischen Nationalbibliothek digitalisiert und wiederum in ihrer Gesamtheit auch online zur Verfügung gestellt. Dabei konnten die einzelnen Scans durch die automatisierte Erkennung (und manuelle Nachbearbeitung) von Bildmerkmalen auf den Bildern digital wieder so aneinandergereiht werden, dass die Karte in einem eigens dafür erstellten Viewer komplett betrachtet werden kann. Schlagworte:",
    "url": "onbkulturerbe.html"
  },
  {
    "id": "esperanto",
    "title": "Esperanto Collection",
    "content": "Die Sammlung von Zeitungsausschnitten des Bestands Hachette an der Sammlung für Plansprachen der Österreichischen Nationalbibliothek, besteht aus etwa 17.000 Artikeln, die aus Zeitschriften stammen, welche in vielen verschiedenen europäischen Ländern im Zeitraum von 1898 bis 1915 veröffentlicht wurden. Die Artikel selbst berichten von Ereignissen und Personen, die mit Esperanto in Verbindung stehen, z.B. Berichte von Esperanto-Weltkongressen, und bieten daher eine hervorragende und einzigartige Gelegenheit, die Geschichte der Esperanto-Bewegung in Europa im frühen 20. Jahrhundert zu untersuchen. In diesem Projekt wurden Vorarbeiten zu einer Pipeline geleistet, die später auf den Bestand Hachette angewendet wurde. Es wurden für die sehr komplexen Aufnahmebögen der Zeitungsausschnitte neue OCR mit einem eigens dafür trainierten Modell erstellt und diese mit Metadaten, die durch Mitarbeiter*innen der Sammlung für Plansprachen zusammengestellt wurden, vereinigt. Die neu erstellte OCR-Pipeline umfasst die Segmentierung der Artikel, die Entfernung von Rändern der Scans, eine Drehung in die Waagerechte, die Texterkennung mit Tesseract und die Erstellung der Daten im ALTO-XML Format und als IIIF-Collection. Schlagworte:",
    "url": "onbkulturerbe.html"
  },
  {
    "id": "eugeniana",
    "title": "Bildklassifikation in digitalen Beständen am Beispiel Bibliotheca Eugeniana Digital",
    "content": "Die Rekonstruktion von historischen Beständen innerhalb der Österreichischen Nationalbibliothek ist eine wichtige Forschungsaufgabe der Bibliothek selbst und ein wichtiger Service für deren Nutzer*innen. Anhand von eindeutigen Klassifikationsmerkmalen innerhalb der Bücher lässt sich die Provenienz oft zurückverfolgen. Innerhalb des Projekts wurden Pipelines und Anwendungsfälle für das Erkennen von Provenienzmerkmalen umgesetzt. Mittels des Workflows gelingt anhand von visuellen Merkmalen (z.B. Wappen, Ex-Libris-Angaben, Supralibros) eine Zuordnung der ehemaligen Besitzer*innen. Dafür wurde mit einem convolutional neural network gearbeitet, das auf diese Erscheinungsmerkmale trainiert wurde und in dafür vordefinierten Seitenbereichen der Bücher danach sucht. Die entwickelte Pipeline wurde später im Projekt Bibliotheca Eugeniana Digital weiterentwickelt und verbessert. Schlagworte:",
    "url": "onbkulturerbe.html"
  },
  {
    "id": "digi16",
    "title": "Digi 16: Druckwerke des 16. Jahrhunderts",
    "content": "Die Universitätsbibliothek Graz verwahrt ca. 13.000 Titel gedruckt im 16. Jahrhundert auf. Diese Werke stammen zum überwiegenden Teil aus den säkularisierten Beständen steirischer Klöster die an die Jesuitenuniversität in Graz übergeben werden mussten. Der restliche Teil spiegelt den Bestandsaufbau und die wissenschaftliche Ausrichtung der damals noch sehr jungen Universität wider. Ausgangslage: UB Graz: Alle bekannten Werke wurden in den vergangenen Jahren zentral an einem Standort (Rara 1) versammelt. Die Katalogsituation und die damit einhergehenden Recherchemöglichkeiten waren für eine Benutzung nicht mehr zeitgemäß. Großteils waren die Werke nur in handgeschriebenen Zettelkatalogen des 19. Jahrhunderts verzeichnet. Viele Werke (besonders beigebundene Titel) wurden in der Vergangenheit bibliographisch nicht als Einheit erkannt oder ob des geringen Seitenumfangs nicht als aufnahmewürdig angesehen. Neben dem bibliographischen Zettelkatalog bewahrt die Abteilung für Sondersammlungen mehrere maschinschriftliche Nebenkarteien zu den Themen: Besitzgeschichte, Einbandkunde, Exlibris u.ä. Ziel war es all diese Informationen in Zukunft benutzerfreundlich im Bibliotheksportal mit einer Recherche abrufbar zu machen. International: Seit mehreren Jahrzehnten gibt es besonders im deutschprachigen Raum mit dem VD 16 und im italienschsprachigen Raum mit edit 16 große nationale Projekte bibliographische Nachschlagewerke aufzubauen. An diese Bibliographien sind wissenschaftliche Projekte mit ihren Beständen gebunden und zitieren auf die einzelnen individuellen Einträge und Werkbeschreibungen. Durch die zunehmende Digitalisierung ist es jetzt auch möglich über die Titelblätter und Fingerprintmethoden hinaus, vorliegende Exemplare sehr exakt miteinander zu vergleichen. Diese Möglichkeiten ermöglichen tiefgehende Analysen zu den Themen Drucklegung, Geschäftsgebarung und Firmenpolitik im 16. Jahrhundert. Projekt: Entwicklung eines Kategorienschemas nach RDA für bibliographische Erschließung: Da es für die Katalogisierung historischer Drucke noch keine Durchführungsanleitungen im Rahmen der RDA für den DACH-Raum gibt, wurde dieses Projekt herangezogen einen Leitfaden (= Kategorienschema) zu entwickeln. Diese Leitfaden wurde im Rahmen der Retrokatalogisierung getestet und den nationalen und übernationalen Gremien zur Verfügung gestellt. Entwicklung eines Beschreibungsschemas für historische Einbände und die Besitzgeschichte. Entwicklung eines Beschreibungsschemas für historische Einbände und die Besitzgeschichte Retrokatalogisierung in der Verbunddatenbank ALMA Ergebnisse sind abrufbar unter: unikat.uni-graz.at Erweiterte Suche – Suchfilter “Standort” – Suchbegriff „ssr1“ (= Sondersammlungen Rara 1) Digitalisierung Alle retrokatalogisierten Werke wurden entweder vollständig oder teildigitalisiert. In unipub und unikat Open Access veröffentlichte Teildigitalisate ersetzen die, für den bibliographischen Nachweis notwendigen, Fingerprint-Formeln. Schlagworte:",
    "url": "digi16.html"
  },
  {
    "id": "hps",
    "title": "Historisch-physikalische Sammlung",
    "content": "Die Historisch-physikalische Sammlung in den Universitätsmuseen der Universität Graz umfasst eine Auswahl von 62 Objekten, die von Mitarbeiter:innen des Instituts für Physik sowie des vormaligen Fachbereichs für Physik der Philosophischen Fakultät der Universität Graz im Laufe der vergangenen vier Jahrhunderte angeschafft beziehungsweise teils auch selbst konstruiert und gebaut wurden. Schwerpunktmäßig ist die Ausstellung dabei auf die Geschichte der Physik des 19. und 20. Jahrhunderts ausgerichtet. Im Rahmen des vom Bundesministerium für Bildung, Wissenschaft und Forschung geförderten Projektes „Digitale Transformation der Österreichischen Geisteswissenschaften“ (DiTAH) wurde von den Universitätsmuseen in Kooperation mit dem Institut Zentrum für Informationsmodellierung (ZIM) die digitale Erfassung und Erschließung dieses Sammlungsbestands durchgeführt, wobei objektbezogene Daten auf Basis der Methodik der Allgemeinen Museologie sowie vor dem Hintergrund ihrer Wissenschafts- und Institutionengeschichte erschlossen, archiviert und über diese Webseite präsentiert werden. Schlagworte:",
    "url": "hps.html"
  },
  {
    "id": "pipelines",
    "title": "Hybrid Pipelines",
    "content": "Das Teilprojekt “Hybrid Pipelines” hatte ursprünglich die Weiterentwicklung der Applikation SpacyApp als flexible hybride Annotationspipeline zum Ziel. Eingehende Recherche hat allerdings ergeben, dass ähnliche Funktionalitäten von bereits bestehenden Lösungen (z.B.: INCEpTION, CATMA, Arborator) angeboten werden. In Folge richtete sich der Fokus des Teilprojektes verstärkt auf die Wiederverwendbarkeit (Reusability) und bessere Nachvollziehbarkeit von Workflows und flexiblen Pipelines – zentrale Themen, welche auch in den Infrastruktur-Projekten CLS INFRA, ATRIUM und OSCARS weiterentwickelt und vorangetrieben werden. In Zusammenarbeit mit dem Projekt CLS INFRA wurde ein neues Konzept für die Erstellung und Definition von Pipelines mit dem Fokus auf Wiederverwendbarkeit entwickelt: VELD – Versioned Executable Logic and Data – ist ein Ansatz, der es mit Hilfe von vorhandenen weit verbreiteten Technologien (docker und git) ermöglicht, flexible Pipelines zu definieren, sie unverändert, oder angepasst in unterschiedlichen technischen Umgebungen auszuführen und alle Aspekte nachvollziehbar zu protokollieren. Diese Pipelines werden aus einfachen Komponenten zusammengesetzt, die entweder Daten oder Funktionalität bereitstellen. Das Konzept wurde durch eine prototypische Referenzimplementierung auf Umsetzbarkeit hin geprüft. In dieser wurden zahlreiche NLP-Pipelines mit verschiedenen historischen Texten als Beispieldaten definiert. Schlagworte:",
    "url": "pipelines.html"
  },
  {
    "id": "cima",
    "title": "The Centre of Image and Material Analysis in Cultural Heritage - Projekte",
    "content": "Im Rahmen von CIMA und der damit einhergehenden interdisziplinären Untersuchung von historischen Handschriften entsteht eine Vielfalt an Mess- und Beschreibungsdaten: diese reichen von Aufnahmen mit verschiedenen Wellenlängen (sog. Multi- und Hyperspektralbilder) über spektroskopische und mikrobiologische Materialanalysen, kodikologische und restauratorische Beschreibungen, bis hin zu Transkriptionen und philologischen Editionen. Schlagworte:",
    "url": "cima.html"
  },
  {
    "id": "gipse",
    "title": "Virtuelles Gipsmuseum",
    "content": "Ziel des Projekts war die Entwicklung eines Virtuellen Museums der Abgusssammlung am Institut für Antike an der Universität Graz. Es umfasste die Digitalisierung (durch FARO Laserscan) der denkmalgeschützten Sammlungsräumlichkeiten im Universitätshauptgebäude, die Kompilierung relevanter archäologischer und sammlungsgeschichtlicher Daten zu den Gipsabgüssen sowie die Einpflegung in GAMS. Zusätzlich wurden im Projekt 3D-Modelle ausgewählter Gipsabgüsse, ein Prototyp für die Präsentation der Daten zu den Abgüssen und ihrer Geschichte erstellt und gemeinsam mit 3D-Beispielmodellen in einem virtuellen Rundgang zur Verfügung gestellt. Der Einsatz dieser Werkzeuge, der vor allem im Bereich der Digitalen Museumswissenschaften anzusiedeln ist, soll den Zugang zu der umfassenden Objektsammlung erleichtern, Interesse an den Objekten und ihrer Geschichte wecken und ihre Sichtbarkeit weiter stärken. Aus diesem Grund werden auch allgemeine Informationen über die Sammlung bereitgestellt. Die Arbeiten werden unter direkter Einbindung von Studierenden durchgeführt und von einschlägigen Lehrveranstaltungen am Institut für Antike und am Institut für Digitale Geisteswissenschaften begleitet, um vor allem die Erstellung von 3D-Modellen sowie die Erfassung von archäologischen Informationen und Daten zu unterstützen. Schlagworte: Gipse Gips, virtuell, virtuelles Museum, virtuelles Museum der Abgusssammlung des INstituts für Antike; Digitalisierung der denkmalgeschützten Sammlungsräumlichkeiten als Ensen+mble; Kompilierung relevanter Eckdaten in ein digitales Archiv, Dokumentation ausgewählter Gipsabdrücke in Form hochaufgelöster 3D-Modelle, Präsentation der Daten und ihrer Geschichte in einem online-Portal; trägt zur Sichtbarkeit einer kompakten Museumssammlung bei; niederschwellige Sichtbarkeit und weiterer Umgang in anderen Kontexten ",
    "url": "gipse.html"
  },
  {
    "id": "dhlehregraz",
    "title": "Digital Humanities Lehre an der Universität Graz",
    "content": "DH Lehre Digital Humanities Lehre an der Universität Graz Als erste österreichische Universität richtete im Studienjahr 2017/18 die Universität Graz ein Masterstudium „Digitale Geisteswissenschaften“ ein. In diesem Studium erwerben Studierende neben theoretischem und methodischem Grundlagenwissen auch praktische Erfahrungen in der wissenschaftlichen Anwendung von modernen IT-Technologien und digitalen Methoden auf Forschungsfragen in den Geisteswissenschaften. Schlagworte: Lehre, Studium, Uni Graz, Digital Humanities",
    "url": "dhlehregraz.html"
  }
]